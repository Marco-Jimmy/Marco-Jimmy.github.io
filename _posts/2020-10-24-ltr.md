---
layout:     post
title:      Learning-to-Rank with Partitioned Preference
subtitle:   Fast Estimation for the Plackett-Luce Model
date:       2020-10-24
author:     JIM
header-img: img/post-bg-desk.jpg
mathjax: true
catalog: true
tags:
    - Foreseer
    - ML
    - Paper
    - Notes
    - Learning-to-Rank	
	- Plackett-Luce Model
---
# Learning-to-Rank with Partitioned Preference
## Task
Rank a list of items for a given context (e.g., a user) based on the featured representation of the items and the context.

## Data
### General
Training data consists of *queries* and *documents* matching them together with relevance degree of each match. It may be prepared manually by human assessors (or raters, as Google calls them), who check results for some queries and determine relevance of each result.
### Partitioned Preference (this paper)
The training data has only partitioned preference. 
* The set of items are sliced into **ordered and disjoint partitions**.
* The ranking of items inside a partition is **unknown**.
* A special case is *top-K ranking*, where the exact order of the top K items is known.

### XML dataset (this paper)
* *XML classification task* requires a ML model to tag the most relevant subset of an extremely large label set.
* special case of ranking with partitioned preference, where the class labels are considered as items, and for each document its relevant labels form one partition and irrelevan labels form another lowered-ranked partition. (binary-partition)

## Approaches

### Pointwise
In this case, it is assumed that **each query-document pair in the training data has a numerical or ordinal score.** Then the learning-to-rank problem can be approximated by a **regression** problem — given a single query-document pair, predict its score.

A number of existing supervised machine learning algorithms can be readily used for this purpose. Ordinal regression and classification algorithms can also be used in pointwise approach when they are used to predict the score of a single query-document pair, and it takes a small, finite number of values.
### Pairwise approach
In this case, the learning-to-rank problem is approximated by a **classification** problem — learning a binary classifier that can tell which document is better in a given pair of documents. The goal is to minimize the average number of inversions in ranking.
### Listwise approach
These algorithms try to directly optimize the value of one of the above evaluation measures, averaged over all queries in the training data. This is difficult because most evaluation measures are not continuous functions with respect to ranking model's parameters, and so continuous approximations or bounds on evaluation measures have to be used.

## Ranking Metric
* Mean average precision (MAP);
* DCG and NDCG;
* Precision@n, NDCG@n, where "@n" denotes that the metrics are evaluated only on top n documents;
* Mean reciprocal rank;
* Kendall's tau;
* Spearman's rho.

## Related Method
### Plackett-Luce (PL) Model
* Listwise approach
* Good at *top-K ranking*
* However, computing the exact likelihood of data with partitioned preference under the PL model requires $O(N+S!)$

## Notations
* $N =$ #items
* $M =$ #partitions
* $S =$ size of the largest partition among the top $M-1$ partitions. 
* $\left \lfloor{N}\right \rfloor = \{1,...,N\}$, the set of $N$ different items.
* $S_1 \prec ... \prec S_M =$ Partitioned preference
* $\Omega(\cdot;\left \lfloor{N}\right \rfloor) =$ a function that maps a partial ranking to the set of all possible permutations of $\left \lfloor{N}\right \rfloor$ that are consistent with the given partial ranking.
* ${w}=$ utility scores vector
* $x=$ item-independent context feature
* $v_i=$ features for item $i$
* $\theta=$ neural network parameters
* $w_i=w_i(x,v_i;\theta)=$ utility score of $i$ for a given context 
* $\sigma(\cdot)=$ a function that maps a set of items to the set of all possible permutations of these items.
* $R_m=\overset{M}{\underset{r=m}{\bigcup}}S_r=$ the set of items that do not belong to the top $m-1$ partitions.
  
## Approach

### Likelihood Function

The likelihood of observing a partitioned preference $S_1\succ\dots\succ S_M$ is given by

$$
P(S_1\succ\dots\succ S_M;w)=\sum_{(i_1,...,i_n)\in\Omega(S_1\succ\dots\succ S_M;\lfloor N\rfloor)}\prod_{l=1}^{N}\dfrac{\exp(w_{i_l})}{\sum_{r=l}^N\exp(w_{i_r})}
$$

With Proposition 1, the above likelihood can be transformed into

$$
\begin{aligned}
& P\left(S_{1} \succ \cdots \succ S_{M} ; \boldsymbol{w}\right) \\
=& \prod_{m=1}^{M-1} P\left(S_{m} \succ R_{m+1} ; \boldsymbol{w}\right) \\
=&\prod_{m=1}^{M-1} \int_{u=0}^{1} \prod_{i \in S_{m}}\left(1-u^{\exp \left(w_{i}-w_{R_{m+1}}\right)}\right) d u \\
\end{aligned}
$$

where $w_{R_{m+1}} =\log \sum_{j \in R_{m+1}} \exp \left(w_{j}\right)$ . 

Furthermore, we have

$$
\begin{aligned}
& P\left(S_{1} \succ \cdots \succ S_{M} ; \boldsymbol{w}\right) \\
=&\left.\prod_{m=1}^{M-1} \int_{u=0}^{1} \prod_{i \in S_{m}}\left(1-u^{\exp \left(w_{i}-w_{R_{m+1}}\right.}\right)\right) d u \\
=& \prod_{m=1}^{M-1} \exp \left(w_{R_{m+1}}+c\right)\int_{v=0}^{1} v^{\exp \left(w_{R_{m+1}}+c\right)-1} \prod_{i \in S_{m}}\left(1-v^{\exp \left(w_{i}+c\right)}\right) d v 
\end{aligned}
$$

where $v=u^{\exp \left(-c-{w}_{R_{m+1}}\right)}$ .

### Implementation of negative log likelihood

The objective function is the negative loss likelihood function. In XML classification task, two partitions, A and S, are used. Moreover, size of S is significantly larger than A. The neg-log-likelihood is:

$$
\begin{aligned}
    &-\log P\left(A \succ S ; \boldsymbol{w}\right) \\
    =& -\log(\exp(w_S+c)\int_0^1v^{\exp(w_S+c)-1}\prod_{i\in A}(1-v^{\exp(w_i+c)})dv)\\
    =& - (w_S+c) -\log(\int_0^1v^{\exp(w_S+c)-1}\prod_{i\in A}(1-v^{\exp(w_i+c)})dv)\\
\end{aligned}
$$

We then focus on the second term

$$
\begin{aligned}
    &\log(\int_0^1v^{\exp(w_S+c)-1}\prod_{i\in A}(1-v^{\exp(w_i+c)})dv)\\
    \simeq&\log\left[\dfrac{1}{T}\sum_{t=1}^Tv_t^{\exp(w_S+c)-1}\prod_{i\in A}(1-v_t^{\exp(w_i+c)})\right]\\
    \simeq&\log\left[\sum_{t=1}^Tv_t^{\exp(w_S+c)-1}\prod_{i\in A}(1-v_t^{\exp(w_i+c)})\right]\\
    =&\sum_{t=1}^T\left[\log v_t^{\exp(w_S+c)-1}+\sum_{i\in A}\log(1-v_t^{\exp(w_i+c)})\right]\\
    =&\sum_{t=1}^T\left[\log v_t^{\exp(w_S+c)-1}+\sum_{i\in A}\log(1-e^{\log v_t\exp(w_i+c)})\right]\\
    =&\sum_{t=1}^T\left[\log v_t^{\exp(w_S+c)-1}+\sum_{i\in A}\log(1-e^{-\exp(\log(-\log v_t))\exp(w_i+c)})\right]\\
    =&\sum_{t=1}^T\left[\log v_t^{\exp(w_S+c)-1}+\sum_{i\in A}\log(1-e^{-\exp(\log(-\log v_t)+(w_i+c))})\right]\\
\end{aligned}
$$

Notice that 

$$\log\left(1-e^{-\exp(\log(-\log v_t)+(w_i+c))}\right)$$ 

is in the form of ```gumbel_log_survival()``` function.

Thus, the final neg-log-likelihood is 

$$
\begin{aligned}
    &-\log P\left(A \succ S ; \boldsymbol{w}\right) \\
    \simeq& - (w_S+c) -\sum_{t=1}^T\left[\log v_t^{\exp(w_S+c)-1}+\sum_{i\in A}\log(1-e^{-\exp(\log(-\log v_t)+(w_i+c))})\right]\\
\end{aligned}
$$

where $w_{S} =\log \sum_{j \in S} \exp \left(w_{j}\right)$ 