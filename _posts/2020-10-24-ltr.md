---
layout:     post
title:      NOTES Learning-to-Rank with Partitioned Preference
subtitle:   Fast Estimation for the Plackett-Luce Model
date:       2020-10-24
author:     JIM
header-img: img/post-bg-desk.jpg
catalog: true
tags:
    - Foreseer
    - ML
    - Paper
    - Notes
    - Ranking
---
- [Learning-to-Rank with Partitioned Preference](#learning-to-rank-with-partitioned-preference)
  - [Task](#task)
  - [Data](#data)
    - [General](#general)
    - [Partitioned Preference (this paper)](#partitioned-preference-this-paper)
    - [XML dataset (this paper)](#xml-dataset-this-paper)
  - [Approaches](#approaches)
    - [Pointwise](#pointwise)
    - [Pairwise approach](#pairwise-approach)
    - [Listwise approach](#listwise-approach)
  - [Ranking Metric](#ranking-metric)
  - [Related Method](#related-method)
    - [Plackett-Luce (PL) Model](#plackett-luce-pl-model)
  - [Notations](#notations)

# Learning-to-Rank with Partitioned Preference
## Task
Rank a list of items for a given context (e.g., a user) based on the featured representation of the items and the context.

## Data
### General
Training data consists of *queries* and *documents* matching them together with relevance degree of each match. It may be prepared manually by human assessors (or raters, as Google calls them), who check results for some queries and determine relevance of each result.
### Partitioned Preference (this paper)
The training data has only partitioned preference. 
* The set of items are sliced into **ordered and disjoint partitions**.
* The ranking of items inside a partition is **unknown**.
* A special case is *top-K ranking*, where the exact order of the top K items is known.
### XML dataset (this paper)
* *XML classification task* requires a ML model to tag the most relevant subset of an extremely large label set.
* special case of ranking with partitioned preference, where the class labels are considered as items, and for each document its relevant labels form one partition and irrelevan labels form another lowered-ranked partition. (binary-partition)

## Approaches

### Pointwise
In this case, it is assumed that **each query-document pair in the training data has a numerical or ordinal score.** Then the learning-to-rank problem can be approximated by a **regression** problem — given a single query-document pair, predict its score.

A number of existing supervised machine learning algorithms can be readily used for this purpose. Ordinal regression and classification algorithms can also be used in pointwise approach when they are used to predict the score of a single query-document pair, and it takes a small, finite number of values.
### Pairwise approach
In this case, the learning-to-rank problem is approximated by a **classification** problem — learning a binary classifier that can tell which document is better in a given pair of documents. The goal is to minimize the average number of inversions in ranking.
### Listwise approach
These algorithms try to directly optimize the value of one of the above evaluation measures, averaged over all queries in the training data. This is difficult because most evaluation measures are not continuous functions with respect to ranking model's parameters, and so continuous approximations or bounds on evaluation measures have to be used.

## Ranking Metric
* Mean average precision (MAP);
* DCG and NDCG;
* Precision@n, NDCG@n, where "@n" denotes that the metrics are evaluated only on top n documents;
* Mean reciprocal rank;
* Kendall's tau;
* Spearman's rho.

## Related Method
### Plackett-Luce (PL) Model
* Listwise approach
* Good at *top-K ranking*
* However, computing the exact likelihood of data with partitioned preference under the PL model requires $O(N+S!)$

## Notations
* $N$ = #items
* $M$ = #partitions
* $S$ = size of the largest partition among the top $M-1$ partitions. 